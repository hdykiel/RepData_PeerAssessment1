E22 <- E22
#Calculations
taxRate <- 0.7
TPC_NB <- avgPremium*(NB/drivenRate)
TPC_RB <- avgPremium*E22*(RB/drivenRate)
TPC <- TPC_NB + TPC_RB
NBA <- taxRate*(acqCost+ TPC)
profit <- (profitExNBA - NBA)
ROS <- ((profit)/requiredSurplus)*100
# from Model ((F8-(0.7*((F9+((I26/C14)*F7)+((I27/C14)*'NB-RB Relat. (needs update)'!E22*F7)))))/F10)
ROS3 <- ((profitExNBA-(taxRate*((acqCost+((NB/drivenRate)*avgPremium)+((RB/drivenRate)*E22*avgPremium)))))/requiredSurplus)
paste(c("Based on the variables provided, ROS would be ", ROS, "or ", ROS3))
}
ROS_comp(1425,403,17,10,100,1488,3403,5.33)
f <- function(x){(1+x)(1+x)}
f <- function(x){results=(1+x)(1+x)}
f2 <- function(x) {results2=(1+x+x^2)}
f(1.23)
f2(1)
f2(1.23)
f(1.23)
f
20*(0.037)
20*(0.4)
20*(0.05)
25*.037
1000/.20
4750/(5000*5)
4500/(5000*5)
200/.1
500000*.037
500000*.04*.18
500000*.045
500000*.04
500000*.04*.2
setwd("C:\Users\n0278855\Dropbox\kaggle_heart")
install.packages("oro.dicom")
library(oro.dicom)
getwd()
dcm <- readDICOMFILE("\\train\\train\\1\\study\\2ch_21")
dcm <- readDICOMFile("\\train\\train\\1\\study\\2ch_21\IM-4572-0001.dcm")
dcm <- readDICOMFile("\\train\\train\\1\\study\\2ch_21\\IM-4572-0001.dcm")
dcm <- readDICOMFile("\\train\\train\\1\\study\\2ch_21\\IM-4572-0001.dcm", skipFirst128=FALSE, DICM=FALSE)
image(t(dcm$img), col=grey(0:64/64), axes=FALSE, xlab="", ylab="")
dcm <- readDICOMFile("\\train\\train\\1\\study\\2ch_21\\IM-4572-0001.dcm", debug=TRUE)
1500*1500
751*4
1097-420
.2*2672
.23*2672
6.99/24
mean(c(11,15.4))
mean(c(13.5,16.7))
4*.20
3303647*.8
3303647*.008
(40272-26429)/(40272)
.8/1.22
(1.22-.8)/1.22
(1.22-.9)/1.22
month <- c("Oct", "Nov", "Dec")
newBusiness <- c(721686,725145,736994)
?data.frame
?as.data.frame
df <- data.frame(month, newBusiness)
df
#KMR EDA
month <- c("Oct", "Nov", "Dec")
newBusiness <- c(721686,725145,736994)
df <- data.frame(month, newBusiness)
for (i in 2:nrow(df)) {
df$newBusinessMonth[i] <- newBusiness[i] - newBusiness[i-1]
}
?trycatch
?tryCatch
#KMR EDA
month <- c("Oct", "Nov", "Dec")
newBusiness <- c(721686,725145,736994)
df <- data.frame(month, newBusiness)
df$newBusiness <- NA
for (i in 2:nrow(df)) {
df$newBusinessMonth[i] <- newBusiness[i] - newBusiness[i-1]
}
#KMR EDA
month <- c("Oct", "Nov", "Dec")
newBusiness <- c(721686,725145,736994)
df <- data.frame(month, newBusiness)
df$newBusiness <- NA
for (i in 2:nrow(df)) {
df$newBusinessMonth[i] <- newBusiness[i]
}
for (i in 1:nrow(df)) {
df$newBusinessMonth[i] <- newBusiness[i]- newBusiness[i-1]
}
?diff
diff(df$newBusiness)
diff(df$newBusiness)
newBusiness <- c(721686,725145,736994)
df <- data.frame(month, newBusiness)
diff(df$newBusiness)
df$newBusiness_diff <- diff(df$newBusiness)
diff(df$newBusiness)
mean(diff(df$newBusiness))
736994-725145
newBusinessPerYear <- 12 * mean(diff(df$newBusiness))
(newBusinessPerYear <- 12 * mean(diff(df$newBusiness)))
4.5*.2
(1.22-.9)/1.22
(.23-.9)/.23
USA_population_2014 <- 318857056; #from census.gov
under_18_percentage <- .231; #from census.gov
USA_adult_population_2014 <- USA_population_2014*under_18_percentage
LM_2015_binds <- 111818
(USA_bindRate <- LM_2015_binds/USA_adult_population_2014*100)
(1.22*12-.9)/(1.22*12)
H3 <- 37
H4 <- 63
AO <- 28
total <- sum(H3,H4,AO)
policies <- c(H3,H4,AO)
total <- sum(policies)
policies/total
percent(policies/total)
library(scales)
percent(policies/total)
df<- data.frame(percent(policies/total))
names(df) <- c('H3', 'H4', 'AO')
df
colnames(percent(policies/total)) <- c('H3', 'H4', 'AO')
colnames(percent(policies/total))
H3 <- 37
H4 <- 63
AO <- 28
policies <- c(H3,H4,AO)
total <- sum(policies)
library(scales)
colnames(percent(policies/total))
(percent(policies/total))
matrix((percent(policies/total)), nrow=1)
colnames(matrix((percent(policies/total)), nrow=1)_ <- c('H3', 'H4', 'AO')
colnames(matrix((percent(policies/total)), nrow=1) <- c('H3', 'H4', 'AO')
)
colnames(matrix((percent(policies/total)), nrow=1)) <- c('H3', 'H4', 'AO')
?"matrix"
colnames(matrix((percent(policies/total)), nrow=1))) <- c('H3', 'H4', 'AO')
colnames(matrix(percent(policies/total), nrow=1)) <- c('H3', 'H4', 'AO')
percent(policies/total)
49+29+22
13.6+14
H3 <- 37
H4 <- 63
AO <- 28
policies <- c(H3,H4,AO)
names <- c('H3', 'H4', 'AO')
total <- sum(policies)
library(scales)
mix <- percent(policies/total)
df <- data.frame(names, mix)
df
16.5/55
500*.17
H3 <- 37
H4 <- 63
AO <- 28
policies <- c(H3,H4,AO)
LOB <- c('H3', 'H4', 'AO')
total <- sum(policies)
library(scales)
mix <- percent(policies/total)
df <- data.frame(LOB, mix)
print(df)
37.5/5
45/7.5
802/940
1185-223
44821-9894
12429926*(.20/100)*(19.84/100)
.20/.51
.42/.6
14308/5111130
14308/5111130*100
1779/1297332*100
names <- c("Mailed","Mailings", "Responses")
df <- data.frame(c('Yes', 5111130, 14308), c('No', 1297332, 1779))
df
names(df) <- names
df <- data.frame(names,c('Yes', 5111130, 14308), c('No', 1297332, 1779))
df
names <- c("Mailed","Mailings", "Responses")
df <- data.frame(names,c('Yes', 5111130, 14308), c('No', 1297332, 1779))
df
mailed <- c('Yes', 'No')
responses <- c(14308,1779)
mailings <- c(5111130,1297332)
df <- data.frame(mailed,responses,mailings)
df
mailed <- c('Yes', 'No')
responses <- c(14308,1779)
groupSize <- c(5111130,1297332)
df <- data.frame(mailed,mailings,responses)
(df <- data.frame(mailed,mailings,responses))
(df <- data.frame(mailed,groupSize,responses))
df$responseRate <- df$responses/groupSize
df
df$responseRate <- df$responses/groupSize*100
df
library(scales)
df$responseRate <- percent(df$responses/groupSize)
df
df[1,"respnseRate"]
df[1,"responseRate"]
df$responseRate[1]
df$responseRate[df$mailed='Yes']
df$responseRate[df$mailed=='Yes']
incrementalRR <- df$responseRate[df$mailed=='Yes'] - df$responseRate[df$mailed=='No']
(df <- data.frame(mailed,groupSize,responses))
df$responseRate <- percent(df$responses/groupSize)
incrementalRR <- df$responseRate[df$mailed=='Yes'] - df$responseRate[df$mailed=='No']
df$responseRate <- df$responses/groupSize
df$responseRate <- df$responses/df$groupSize
incrementalRR <- df$responseRate[df$mailed=='Yes'] - df$responseRate[df$mailed=='No']
df
incrementalRR
incrementalRR*100
incrementalRR/df$responseRate[df$mailed=='Yes']
drivenRate <- incrementalRR/df$responseRate[df$mailed=='Yes']
fieldResponses <- c(2629,544)
drcResponses <- c(7765,561)
(df <- data.frame(mailed,groupSize,totalResponses, fieldResponses, drcResponses,internetResponses))
totalResponses <- c(14308,1779)
fieldResponses <- c(2629,544)
drcResponses <- c(7765,561)
internetResponses <- c(3914,674)
groupSize <- c(5111130,1297332)
#save to data frame
(df <- data.frame(mailed,groupSize,totalResponses, fieldResponses, drcResponses,internetResponses))
df$fieldRR <- df$fieldResponses/groupSize
df
df$dcrRR <- df$drcResponses/df$groupSize
groupSize
fieldResponses/groupSize
df$internetRR <- df$internetResponses/df$groupSize
df
channel <- c('All', 'Field', 'DRC', 'Internet')
groupSize <- seq(5111130, length(channel))
groupsize
groupSize
lenghth(channe;)
lenghth(channel)
length(channel)
groupSize <- rep(5111130, length(channel))
groupSize
groupSize <- c(rep(5111130, length(channel), rep(1297332, length(channel)))
)
groupSize <- c(rep(5111130, length(channel), rep(1297332, length(channel)))
groupSize
groupSize
rep(1297332, length(channel))
groupSize <- c(rep(5111130, length(channel), rep(1297332, length(channel))))
groupSize <- c(rep(5111130, length(channel)), rep(1297332, length(channel)))
groupSize
channel <- rep(c('All', 'Field', 'DRC', 'Internet'),2)
groupSize <- c(rep(5111130, length(channel)/2), rep(1297332, length(channel)/2))
df2 <- data.frame(channel, groupSize)
df2
mailed <- c(rep('Yes',4),rep('No',4))
df2 <- data.frame(channel, mailed, groupSize)
(df2 <- data.frame(channel, mailed, groupSize))
responses <- c(14308,	2629,	7765,	3914,	1779,	544,	561,	674)
(df2 <- data.frame(channel, mailed, groupSize))
(df2 <- data.frame(channel, mailed, groupSize, responses))
df$RR <- responses/groupSize
(df <- data.frame(channel, mailed, groupSize, responses))
df$RR <- df$responses/df$groupSize
(df <- data.frame(channel, mailed, gr)
(df$RR <- df$responses/df$groupSize)
)
(df$RR <- df$responses/df$groupSize)
df
?subset
df_noMail <- subset(df, mailed == 'No')
(df_noMail <- subset(df, mailed == 'No'))
colnames(df_noMail)[RR]
colnames(df_noMail)[5]
colnames(df_noMail)["RR"]
colnames(df_noMail)[which(names(df_noMail) == 'RR')]
colnames(df_noMail)[which(names(df_noMail) == 'RR')] <- "baseRR"
df_noMail
colnames(df_noMail)
names(df_noMail) %in% c("RR")
names(df_noMail) %in% c("baseRR")
which(names(df_noMail) %in% c("baseRR"))
df_noMail <- df_noMail[ , which(names(df_noMail) %in% c('baseRR', 'channel'))]
df_noMail
df <- merge(x = df, y = df_noMail, by = "channel", all.x = TRUE) #left inner join to get baseRR value
df
(df_Mail <- subset(df, mailed == 'Yes')) #subset no mail
df <- merge(x = df_Mail, y = df_noMail, by = "channel", all.x = TRUE) #left inner join to get baseRR value
df
channel <- rep(c('All', 'Field', 'DRC', 'Internet'),2)
groupSize <- c(rep(5111130, length(channel)/2), rep(1297332, length(channel)/2))
mailed <- c(rep('Yes',4),rep('No',4))
responses <- c(14308,	2629,	7765,	3914,	1779,	544,	561,	674)
#save to data frame
(df <- data.frame(channel, mailed, groupSize, responses))
(df$RR <- df$responses/df$groupSize)
channel <- rep(c('All', 'Field', 'DRC', 'Internet'),2)
mailed <- c(rep('Yes',4),rep('No',4))
groupSize <- c(rep(5111130, length(channel)/2), rep(1297332, length(channel)/2))
responses <- c(14308,	2629,	7765,	3914,	1779,	544,	561,	674)
#save to data frame
(df <- data.frame(channel, mailed, groupSize, responses))
df$RR <- df$responses/df$groupSize
(df_noMail <- subset(df, mailed == 'No')) #subset no mail
(df_Mail <- subset(df, mailed == 'Yes')) #subset  mail
colnames(df_noMail)[which(names(df_noMail) == 'RR')] <- "baseRR" #rename column
df_noMail <- df_noMail[ , which(names(df_noMail) %in% c('baseRR', 'channel'))]
df <- merge(x = df_Mail, y = df_noMail, by = "channel", all.x = TRUE) #left inner join to get baseRR value
df
channel <- rep(c('All', 'Field', 'DRC', 'Internet'),2)
groupSize <- c(rep(5111130, length(channel)/2), rep(1297332, length(channel)/2))
mailed <- c(rep('Yes',4),rep('No',4))
#save to data frame
responses <- c(14308,	2629,	7765,	3914,	1779,	544,	561,	674)
(df <- data.frame(channel, mailed, groupSize, responses))
df$RR <- df$responses/df$groupSize
(df_noMail <- subset(df, mailed == 'No')) #subset no mail
(df_Mail <- subset(df, mailed == 'Yes')) #subset  mail
colnames(df_noMail)[which(names(df_noMail) == 'RR')] <- "baseRR" #rename column
df_noMail <- df_noMail[ , which(names(df_noMail) %in% c('baseRR', 'channel'))] #drop columns
df_Mail <- df_Mail[ , -which(names(df_noMail) %in% c('groupSize', 'responses'))] #drop columns
df <- merge(x = df_Mail, y = df_noMail, by = "channel", all.x = TRUE) #left inner join to get baseRR value
(df_Mail <- subset(df, mailed == 'Yes')) #subset  mail
(df_noMail <- subset(df, mailed == 'No')) #subset no mail
df_noMail <- df_noMail[ , which(names(df_noMail) %in% c('baseRR', 'channel'))] #drop columns
df_Mail <- df_Mail[ , -which(names(df_noMail) %in% c('groupSize', 'responses'))] #drop columns
df_Mail
-which(names(df_noMail) %in% c('groupSize', 'responses'))
df_Mail <- df_Mail[ , -which(names(df_Mail) %in% c('groupSize', 'responses'))] #drop columns
df <- merge(x = df_Mail, y = df_noMail, by = "channel", all.x = TRUE) #left inner join to get baseRR value
df
(df_noMail <- subset(df, mailed == 'No')) #subset no mail
(df_Mail <- subset(df, mailed == 'Yes')) #subset  mail
colnames(df_noMail)[which(names(df_noMail) == 'RR')] <- "baseRR" #rename column
df_noMail <- df_noMail[ , which(names(df_noMail) %in% c('baseRR', 'channel'))] #drop columns
df_Mail <- df_Mail[ , -which(names(df_Mail) %in% c('groupSize', 'responses'))] #drop columns
df <- merge(x = df_Mail, y = df_noMail, by = "channel", all.x = TRUE) #left inner join to get baseRR value
df
df$incRR <- df$RR - df$baseRR
df
df$incRR <- percent(df$RR - df$baseRR)
df
df$incRR <- (df$RR - df$baseRR)
df$drivenRate <- df$incRR/df$RR
df
df$drivenRate <- percent(df$incRR/df$RR)
df
R.session()
install.packages("knitr")
install.packages("htmltools")
install.packages("yaml")
install.packages("caTools")
install.packages("rmarkdown")
6000*.12
6000*.12-2000
(6000*.12-2000)/400
profitxNBA <- 1000
qb <- 200
reqSurplus <- 3000
targetROS <- 0.12
TPC_allowance <- qb - ((targetROS*reqSurplus) - profitxNBA)
print(TPC_allowance)
ROS <- (profitxNBA - qb - TPC_allowance)/reqSurplus
TPC_allowance <-  ((targetROS*reqSurplus) - profitxNBA) - qb
print(TPC_allowance)
ROS <- (profitxNBA - qb - TPC_allowance)/reqSurplus
(ROS)
TPC_allowance <-  ((targetROS*reqSurplus) - profitxNBA) + qb
print(TPC_allowance)
ROS <- (profitxNBA - qb - TPC_allowance)/reqSurplus
(ROS)
TPC_allowance <-  - ((targetROS*reqSurplus) - profitxNBA) - qb
print(TPC_allowance)
ROS <- (profitxNBA - qb - TPC_allowance)/reqSurplus
(ROS)
TPC_allowance <-  profitxNBA - (targetROS*reqSurplus)  - qb
print(TPC_allowance)
profitxNBA <- 1000
qb <- 200
reqSurplus <- 3000
1000-200-440
360/3000
Sys.Date()
setwd("C:/Users/n0278855/Dropbox/Coursera Data Science/reproducibleResearch/assignment2")
url <- 'https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2'
download.file(url, 'Data/download.csv.bz2')
df <- read.csv(bzfile('Data/download.csv.bz2'))
head(df)
summary(df)
dim(df) #print dimensions
library(Amelia) #required for missmap()
install.packages("Amelia")
missmap(df, main="[TITLE: Missing Values", col=c("red","black"), legends = FALSE)
library(Amelia) #required for missmap()
missmap(df, main="[TITLE: Missing Values", col=c("red","black"), legends = FALSE)
?missmap
View(df_Mail)
install.packages("cowplot")
df <- read.csv('Data/activity.csv') #Load Data
setwd("C:/Users/Hadrien/Dropbox/Coursera Data Science/reproducibleResearch/assignment1/RepData_PeerAssessment1-master")
setwd("C:/Users/n0278855/Dropbox/Coursera Data Science/reproducibleResearch/assignment1/RepData_PeerAssessment1-master")
df <- read.csv('Data/activity.csv') #Load Data
df2 <- df[!is.na(df$steps), ] #remove NAs
df2_summarized <- ddply(df2, c("date"), summarize, sumSteps = sum(steps)) #summarize
```
library(ggplot2)
library(plyr)
library(mice) #used to impute missing values
library(chron)
library(cowplot)#needed to graph multiple plots
df2_summarized <- ddply(df2, c("date"), summarize, sumSteps = sum(steps)) #summarize
```
df <- read.csv('Data/activity.csv') #Load Data
df2 <- df[!is.na(df$steps), ] #remove NAs
df2_summarized <- ddply(df2, c("date"), summarize, sumSteps = sum(steps)) #summarize
qplot(steps,
xlab='Total Steps Each Day',
ylab='Frequency')
qplot(df2$steps,
xlab='Total Steps Each Day',
ylab='Frequency')
qplot(df2_summarized$sumSteps,
xlab='Total Steps Each Day',
ylab='Frequency')
setwd("C:/Users/n0278855/Desktop/Projects/Model/scoredDataSets2016")
setwd("C:/Users/n0278855/Desktop/Projects/Model/scoredDataSets2016")
h3_lm <- read.csv('eg_h3_pl_strategic_final.csv')
h3_lm <- read.csv('data/eg_h3_pl_strategic_final.csv')
rm(list = ls())
setwd("C:\\Users\\n0278855\\Desktop\\SAS\\Credibility Adjustment Exercise")
auto_scored <- read.csv("Data/strat_auto.csv") #strategic data set
auto_scored$Scored.Premium <- gsub("(\\$|,)", "", as.character(auto_scored$Premium)) #remove $ and ,
auto_scored$Scored.Premium <- as.numeric(auto_scored$Scored.Premium) #convert to numeric
auto_scored$Prem_at_Inception_Ann <- gsub("(\\$|,)", "", as.character(auto_scored$Prem_at_Inception_Ann)) #remove $ and ,
auto_scored$Prem_at_Inception_Ann <- as.numeric(auto_scored$Prem_at_Inception_Ann) #convert to numeric
auto_scored$Surplus <- gsub("(\\$|,)", "", as.character(auto_scored$Surplus.Rebased)) #remove $ and ,
auto_scored$Surplus <- as.numeric(auto_scored$Surplus) #convert to numeric
auto_scored$ProfitxNBA <- gsub("(\\$|,)", "", as.character(auto_scored$ProfitxNBA.Rebased)) #remove $ and ,
auto_scored$ProfitxNBA <- as.numeric(auto_scored$ProfitxNBA) #convert to numeric
auto_scored$Scored.Loss.Ratio <- as.numeric(sub("%", "", auto_scored$Scored_LR)) #Remove %, convert to numeric
auto_scored$Scored.Persistency <- as.numeric(sub("%", "", auto_scored$Persistency))/100 #Remove %, convert to numeric
setwd("//lm/central/Permkt/Permkt-Private/Distribution_Insights/Channel Insights/Distribution Ops/Partnerships/EA Tool/Model Update v23/scoredPolicies/Scripts")
setwd("//lm/central/Permkt/Permkt-Private/Distribution_Insights/Channel Insights/Distribution Ops/Partnerships/EA Tool/Model Update v23/scoredPolicies")
df <- read.csv('Data/gridwork_existingPermutations.csv')
head(df)
head(unique(df))
head(unique(df$decileBucket))
head(unique(df))
names(df)
nrow(df)
nrow(unique(df))
head(permutations)
permutations <- expand.grid(channel, decileBucket, state)
channel <- unique(df$Channel) #save all unique channel values to a vector
decileBucket <- unique(df$decileBucket) #save all unique decileBucket values to a vector
state <- c(state.abb, "DC")
#Create data frame with all permutations
permutations <- expand.grid(channel, decileBucket, state)
names(permutations) <- c("Channel", "decileBucket", "State")
head(permutations)
names(df)
channel <- unique(df$channel) #save all unique channel values to a vector
decileBucket <- unique(df$decileBucket) #save all unique decileBucket values to a vector
state <- c(state.abb, "DC")
#Create data frame with all permutations
permutations <- expand.grid(channel, decileBucket, state)
names(permutations) <- c("channel", "decileBucket", "state")
head(permutations)
(total_possible_permutations <- nrow(permuations))
(total_possible_permutations <- nrow(permutations))
(num_of_permutations <- nrow(df))
addl_permutations <- total_possible_permutations - num_of_permutations
(addl_permutations <- total_possible_permutations - num_of_permutations)
permutations <- permutations[order(channel,decileBucket,state),] #sort table
permutations_sorted <- permutations[order(channel,decileBucket,state),] #sort table
permutations_sorted <- permutations[order(channel,decileBucket,state)] #sort table
permutations_sorted <- permutations[order(permutations$channel,permutations$decileBucket,permuations$state)] #sort table
permutations_sorted <- permutations[order(permutations$channel,permutations$decileBucket,permutations$state)] #sort table
permutations_sorted <- permutations[order(permutations$channel,permutations$decileBucket,permutations$state)] #sort table
permutations_sorted <- permutations[order(permutations$channel,permutations$decileBucket,permutations$state).] #sort table
permutations_sorted <- permutations[order(permutations$channel,permutations$decileBucket,permutations$state),] #sort table
write.csv(permutations_sorted, 'Data/allPossiblePermutations.csv')
write.csv(permutations_sorted, 'Data/allPossiblePermutations.csv', row.names = FALSE)
write.csv(permutations_sorted, 'Data/allPossiblePermutations.csv', row.names = FALSE)
setwd("C:/Users/n0278855/Dropbox/Coursera Data Science/reproducibleResearch/assignment1/RepData_PeerAssessment1-master")
df <- read.csv('Data/activity.csv') #Load Data
df2 <- df[!is.na(df$steps), ] #remove NAs
df2_summarized <- ddply(df2, c("date"), summarize, sumSteps = sum(steps)) #summarize
library(ggplot2)
library(plyr)
library(mice) #used to impute missing values
library(chron)
library(cowplot)#needed to graph multiple plots
df2_summarized <- ddply(df2, c("date"), summarize, sumSteps = sum(steps)) #summarize
qplot(df2_summarized$sumSteps,
xlab='Total Steps Each Day',
ylab='Frequency')
hist <- ggplot(data=df2_summarized, mapping = aes(x=date, y=sumSteps)) +
geom_bar(stat="identity", fill = 'blue') +
theme(axis.text.x = element_text(angle = 90)) + #rotate x axis labels
ggtitle('Steps Per Day') +
theme(plot.title = element_text(face='bold', size=16))
